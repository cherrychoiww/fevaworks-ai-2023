{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using the Computer Vision API\n",
    "The techniques used so far in this notebook show how you can perform simple image amnipulation and apply some popular algorithms to analyze images. More complex image analysis capabilities are encapsulated in the Computer Vision API cognitive service.\n",
    "\n",
    "### Create a Computer Vision API Service\n",
    "To provision a Computer Vision API service in your Azure subscription, Follow these steps:\n",
    "\n",
    "1. Open another browser tab and navigate to https://portal.azure.com.\n",
    "2. Sign in using your Microsoft account.\n",
    "3. Click **+ New**, and in the **AI + Cognitive Services** category, click **See all**.\n",
    "4. In the list of cognitive services, click **Computer Vision API**.\n",
    "5. In the **Computer Vision API** blade, click **Create**.\n",
    "6. In the **Create** blade, enter the following details, and then click **Create**\n",
    "  * **Name**: A unique name for your service.\n",
    "  * **Subscription**: Your Azure subscription.\n",
    "  * **Location**: Choose the Azure datacenter location where you want to host your service.\n",
    "  * **Pricing tier**: Choose the F0 pricing tier.\n",
    "  * **Resource Group**: Choose the existing resource group you created in the previous lab (or create a new one if you didn't complete the previous lab)\n",
    "  * Read the notice about the use of your data, and select the checkbox.\n",
    "7. Wait for the service to be created.\n",
    "8. When deployment is complete, click **All Resources** and then click your Computer Vision service to open its blade.\n",
    "9. In the blade for your Computer Vision service, note the **Endpoint** URL. Then assign the base URI (*location*.api.cognitive.microsoft.com) for your service to the **visionURI** variable in the cell below.\n",
    "10. In the blade for your Computer Vision service, click **Keys** and then copy **Key 1** to the clipboard and paste it into the **visionKey** variable assignment value in the cell below. \n",
    "11. Run the cell below to assign the variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visionURI = 'YOUR_COMPUTER_VISION_API_ENDPOINT'\n",
    "visionKey = 'YOUR_COMPUTER_VISION_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get An Image from a URL\n",
    "Run the code in the cell below to retrieve the image description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "img_url = 'https://umbrellacreative.com.au/wp-content/uploads/2020/01/hide-the-pain-harold-why-you-should-not-use-stock-photos-1024x683.jpg'\n",
    "\n",
    "# Get the image and show it\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Computer Vision API to Get Image Features\n",
    "The Computer Vision API uses a machine learning model that has been trtained with millions of images. It can extract features from images and return a suggested description, as well as details about the image file and a suggested list of \"tags\" that apply to it.\n",
    "\n",
    "Run the cell below to see what caption the Computer Vision API suggests for the image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your API endpoint and key\n",
    "endpoint = visionURI\n",
    "subscription_key = visionKey\n",
    "\n",
    "# Send a POST request to the API with the image URL\n",
    "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "params = {\"visualFeatures\": \"Description\"}\n",
    "data = {\"url\": img_url}\n",
    "response = requests.post(endpoint + \"/vision/v3.2/analyze\", headers=headers, params=params, json=data)\n",
    "\n",
    "# Parse the JSON response and extract the alt text\n",
    "alt_text = json.loads(response.text)[\"description\"][\"captions\"][0][\"text\"]\n",
    "\n",
    "# Print the alt text\n",
    "print(\"Alt text:\", alt_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read printed and handwritten text\n",
    "Run the code in the cell below to retrieve the text in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "subscription_key = visionKey\n",
    "endpoint = visionURI\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''\n",
    "\n",
    "'''\n",
    "OCR: Read File using the Read API, extract text - remote\n",
    "This example will extract text in an image, then print results, line by line.\n",
    "This API call can also extract handwriting style text (not shown).\n",
    "'''\n",
    "print(\"===== Read File - remote =====\")\n",
    "# Get an image with text\n",
    "read_image_url = \"https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/images/handwritten-note.jpg\"\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "read_response = computervision_client.read(read_image_url,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(line.bounding_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the code above and amend it to use Custom Vision Prediction API\n",
   ]
  },
  ,
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your API endpoint and key\n",
    "endpoint = visionURI\n",
    "subscription_key = visionKey\n",
    "\n",
    "# Send a POST request to the API with the image URL\n",
    "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "params = {\"visualFeatures\": \"Description\"}\n",
    "data = {\"url\": img_url}\n",
    "response = requests.post(   , headers=  , params=  , json=data  )\n",
    "\n",
    "# Parse the JSON response and extract the alt text\n",
    "alt_text = \n",
    "\n",
    "# Print the alt text\n",
    "print(\"Alt text:\", alt_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
